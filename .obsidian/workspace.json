{
  "main": {
    "id": "5c1e94194419c0a6",
    "type": "split",
    "children": [
      {
        "id": "a348cae9407d1c44",
        "type": "tabs",
        "children": [
          {
            "id": "0a219b3fdc25e297",
            "type": "leaf",
            "state": {
              "type": "image",
              "state": {
                "file": "Papers/images/Pasted image 20250625232934.png"
              },
              "icon": "lucide-image",
              "title": "Pasted image 20250625232934"
            }
          },
          {
            "id": "e5f0b0eefdcc5fff",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Papers/GFlowVLM Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "GFlowVLM Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks"
            }
          }
        ],
        "currentTab": 1
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "046dfe82d1f4a896",
    "type": "split",
    "children": [
      {
        "id": "eae7c7bfb8959cfd",
        "type": "tabs",
        "children": [
          {
            "id": "9933c391b89e469d",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical",
                "autoReveal": false
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "bfd2ce7a6c11163c",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "099a404aa301447a",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "right": {
    "id": "283c5d567c39b5b1",
    "type": "split",
    "children": [
      {
        "id": "cd4c8f65639609f0",
        "type": "tabs",
        "children": [
          {
            "id": "47184f5c5dd552b6",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "Backlinks"
            }
          },
          {
            "id": "ff0a95c3362c1f8e",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "Outgoing links"
            }
          },
          {
            "id": "6bfad792a0c8a51f",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true,
                "showSearch": false,
                "searchQuery": ""
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "06bad1f8c6ca3825",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "followCursor": false,
                "showSearch": false,
                "searchQuery": ""
              },
              "icon": "lucide-list",
              "title": "Outline"
            }
          },
          {
            "id": "2a646efef78f3eea",
            "type": "leaf",
            "state": {
              "type": "git-view",
              "state": {},
              "icon": "git-pull-request",
              "title": "Source Control"
            }
          }
        ],
        "currentTab": 4
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false,
      "obsidian-git:Open Git source control": false,
      "obsidian-excalidraw-plugin:New drawing": false
    }
  },
  "active": "e5f0b0eefdcc5fff",
  "lastOpenFiles": [
    "Papers/ARGUS Vision-Centric Reasoning with Grounded Chain-of-Thought.md",
    "Papers/GFlowVLM Enhancing Multi-step Reasoning in Vision-Language Models with Generative Flow Networks.md",
    "Ideas/CoT Dataset.md",
    "Papers/VoCoT.md",
    "Ideas/CoT Dataset Infographics.md",
    "Papers/images/Pasted image 20250703133217.png",
    "Papers/Reasoning to Edit Hypothetical Instruction-Based Image Editing with Visual Reasoning.md",
    "Ideas/Learning from Teaching Videos..md",
    "To Read.md",
    "Ideas/CoT in diffusion Models.md",
    "Ideas/Meeting Notes.md",
    "Ideas/MintCoT Region Proposal.md",
    "Ideas/Interleaved Tokens for Reasoing.md",
    "Papers/images/Pasted image 20250625232934.png",
    "Ideas/Latent CoT Alignment.md",
    "Papers/What LVLM looks at when Answering Question.md",
    "Papers/Open-Vocabulary Attention Maps.md",
    "Ideas/Visualizing Attention Maps.md",
    "Ideas/Latent CoT Workflow.canvas",
    "Ideas/Latent CoT in AR Models.md",
    "Papers/Visual CoT.md",
    "Papers/Vision as a Dialect.md",
    "Ideas",
    "Papers/images/Drawing 2025-06-25 23.45.58.excalidraw.md",
    "Excalidraw/Drawing 2025-06-25 23.48.36.excalidraw.md",
    "Excalidraw/Drawing 2025-06-25 23.48.42.excalidraw.md",
    "Papers/images/Pasted image 20250625234415.png",
    "Papers/images/Pasted image 20250625232243.png",
    "Excalidraw",
    "Papers/SigLIP2.md",
    "Papers/Untitled 1.md",
    "2025-06-25.md",
    "Papers/images",
    "Welcome.md",
    "Papers"
  ]
}